{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import powerlaw\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import geopy.distance\n",
    "import geopandas as gpd"
   ],
   "id": "a8221127b0a198ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load OpenFlights airport data from the CSV file\n",
    "OF_airports = pd.read_csv(\n",
    "    \"data/airports.dat\",  # Path to the airports data file\n",
    "    header=None,  # Indicates there are no headers in the file\n",
    "    names=[\"Airport ID\", \"Name\", \"City\", \"Country\", \"IATA/FAA\",\n",
    "           \"ICAO\", \"Latitude\", \"Longitude\", \"Altitude\", \"Timezone\", \"DST\",\n",
    "           \"Tz database timezone\", \"Type\", \"Source\"],  # Custom column names in the CSV of airports\n",
    "    sep=\",\"  # Columns are separated by commas\n",
    ")\n",
    "\n",
    "# Load OpenFlights routes data from the CSV file\n",
    "OF_routes = pd.read_csv(\n",
    "    \"data/routes.dat\",  # Path to the routes data file\n",
    "    header=None,  # Indicates there are no headers in the file\n",
    "    names=[\"Airline\", \"Airline ID\", \"Source airport\", \"Source airport ID\",\n",
    "           \"Destination airport\", \"Destination airport ID\",\n",
    "           \"Codeshare\", \"Stops\", \"Equipment\"]  # Custom column names in the CSV of the routes\n",
    ")\n",
    "\n",
    "# Filter and clean OpenFlights data\n",
    "OF_routes = OF_routes[OF_routes['Codeshare'].notnull()]  # Keep only rows with non-null codeshare values\n",
    "OF_routes = OF_routes[OF_routes['Source airport ID'] != \"\\\\N\"]  # Exclude rows where Source airport ID is missing\n",
    "OF_routes = OF_routes[OF_routes['Destination airport ID'] != \"\\\\N\"]  # Exclude rows where Destination airport ID is missing\n",
    "OF_routes = OF_routes[OF_routes['Source airport ID'] != OF_routes['Destination airport ID']]  # Exclude self-loops (routes where source = destination)\n",
    "\n",
    "# Create weighted OpenFlights network\n",
    "# Based on the route we weighted it\n",
    "OF_routes = OF_routes.groupby(['Source airport ID', 'Destination airport ID']) \\\n",
    "    .size() \\\n",
    "    .reset_index(name='w')  # Count the number of routes between each pair of airports and assign as weight\n",
    "OF_routes.columns = ['i', 'j', 'w']  # Rename columns for clarity\n",
    "OF_routes['i'] = OF_routes['i'].astype(int)  # Ensure the source airport IDs are integers\n",
    "OF_routes['j'] = OF_routes['j'].astype(int)  # Ensure the destination airport IDs are integers\n",
    "OF_routes['w'] = OF_routes['w'].astype(int)  # Ensure the weights are integers\n",
    "\n",
    "# Symmetrize the network by summing the weights of bidirectional edges\n",
    "OF_routes = (\n",
    "    pd.concat([\n",
    "        OF_routes,  # Original data\n",
    "        OF_routes.rename(columns={'i': 'j', 'j': 'i'})  # Swap source and destination columns\n",
    "    ])\n",
    "    .groupby(['i', 'j'], as_index=False)\n",
    "    .agg({'w': 'sum'})  # Sum weights of bidirectional edges\n",
    ")\n",
    "\n",
    "# Keep only one direction of the edge (i < j)\n",
    "OF_routes = OF_routes[OF_routes['i'] < OF_routes['j']]\n",
    "\n",
    "# Filter OF_routes to keep only the routes with airports listed in OF_airports\n",
    "OF_routes = OF_routes[OF_routes['i'].isin(OF_airports['Airport ID'])]  # Keep edges where the source airport exists in the airport dataset\n",
    "OF_routes = OF_routes[OF_routes['j'].isin(OF_airports['Airport ID'])]  # Keep edges where the destination airport exists in the airport dataset\n",
    "\n",
    "# Build the OpenFlights graph\n",
    "OF_graph = nx.Graph()  # Initialize an undirected graph\n",
    "for _, row in OF_routes.iterrows():\n",
    "    source_cords = (OF_airports.loc[OF_airports['Airport ID'] == row['i'], 'Latitude'].values[0],\n",
    "                    OF_airports.loc[OF_airports['Airport ID'] == row['i'], 'Longitude'].values[0])\n",
    "    dest_cords = (OF_airports.loc[OF_airports['Airport ID'] == row['j'], 'Latitude'].values[0],\n",
    "                    OF_airports.loc[OF_airports['Airport ID'] == row['j'], 'Longitude'].values[0])\n",
    "    distance = geopy.distance.geodesic( source_cords, dest_cords).km\n",
    "    OF_graph.add_edge(int(row['i']), int(row['j']), weight=row['w'], distance=distance)  # Add edges with weights to the graph\n"
   ],
   "id": "8cf6a1a11248cb9e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # Filter the graph to keep only the largest connected component\n",
    "OF_graph = OF_graph.subgraph(max(nx.connected_components(OF_graph), key=len))\n",
    "\n",
    "# # Print the number of nodes in the largest connected component\n",
    "# print(f'Number of nodes in the largest connected component: {len(list_of_component[0])}')\n",
    "# # Keep only the largest connected component\n",
    "# OF_graph = OF_graph.subgraph(list_of_component[0])\n",
    "\n",
    "# Print the number of nodes and edges\n",
    "print(f'Number of nodes: {OF_graph.number_of_nodes()}')\n",
    "print(f'Number of edges: {OF_graph.number_of_edges()}')\n"
   ],
   "id": "557df9a6e2de0e39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# create a dictionary in which the keys are the airport name and the values are the value of the airport in df\n",
    "airport_dict = OF_airports.set_index('Airport ID').T.to_dict()\n",
    "\n",
    "# set the attribute for each node in the graph\n",
    "nx.set_node_attributes(OF_graph, airport_dict)"
   ],
   "id": "fe09051e9b20f3bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# remove low-degree nodes\n",
    "G = OF_graph.copy()\n",
    "low_degree = [n for n, d in G.degree() if d < 10]\n",
    "G.remove_nodes_from(low_degree)\n",
    "labels = nx.get_node_attributes(G, 'City')\n",
    "\n",
    "# compute centrality\n",
    "centrality = nx.betweenness_centrality(G, weight='distance')\n",
    "# compute community structure\n",
    "lpc = nx.community.label_propagation_communities(G)\n",
    "community_index = {n: i for i, com in enumerate(lpc) for n in com}\n",
    "\n",
    "#### draw graph ####\n",
    "fig, ax = plt.subplots(figsize=(30, 15))\n",
    "pos = nx.spring_layout(G, k=11, seed=4572321, weight='weight', iterations=1000, scale=15)\n",
    "node_color = [community_index[n] for n in G]\n",
    "node_size = [v * 20000 for v in centrality.values()]\n",
    "nx.draw_networkx(\n",
    "    G,\n",
    "    pos=pos,\n",
    "    with_labels=True,\n",
    "    # with_labels=False,\n",
    "    labels=labels,\n",
    "    node_color=node_color,\n",
    "    node_size=node_size,\n",
    "    edge_color=\"gainsboro\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "\n",
    "# Resize figure for label readability\n",
    "ax.margins(0.1, 0.05)\n",
    "fig.tight_layout()\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ],
   "id": "cdf4ebb4b2ed5f20",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "labels = nx.get_node_attributes(OF_graph, 'Name')\n",
    "fig = plt.figure(figsize=(120, 80))\n",
    "# Plot the graph with more space between nodes\n",
    "# nx.draw_networkx(OF_graph, node_size=10, edge_color='gray', alpha=0.5, with_labels=True, labels=labels)\n",
    "nx.draw_networkx(OF_graph, node_size=10, edge_color='gray', alpha=0.5, with_labels=False)\n",
    "plt.title('Airport and flight network', fontsize=15)\n",
    "plt.savefig('images/networkx_graph.png')\n",
    "plt.show()"
   ],
   "id": "c44fb9ae12385c76",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for node in OF_graph.nodes():\n",
    "    x = airport_dict[node]['Longitude']\n",
    "    y = airport_dict[node]['Latitude']\n",
    "    pos = (x, y)\n",
    "    OF_graph.nodes[node]['pos'] = pos\n",
    "\n",
    "# Ottieni le posizioni dei nodi\n",
    "pos = nx.get_node_attributes(OF_graph, 'pos')\n",
    "labels = nx.get_node_attributes(OF_graph, 'City')\n",
    "bbox = dict(boxstyle=\"round\", ec=\"white\", fc=\"white\", alpha=0.3)\n",
    "\n",
    "# Disegna il grafo\n",
    "#plt.figure(figsize=(100, 50))\n",
    "url = \"https://naciscdn.org/naturalearth/110m/cultural/ne_110m_admin_0_countries.zip\"\n",
    "world: gpd.GeoDataFrame = gpd.read_file(url)\n",
    "world.plot(figsize=(90,40), edgecolor='gray', color='gray', alpha=0.5)\n",
    "\n",
    "nx.draw_networkx_nodes(OF_graph, pos,node_color='red', node_size=90, margins=0)\n",
    "nx.draw_networkx_edges(OF_graph, pos, alpha=0.1)\n",
    "nx.draw_networkx_labels(OF_graph, pos, labels=labels, font_size=10, font_color='black', bbox=bbox)\n",
    "plt.title('Airport and flight network', fontsize=15)\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/networkx_draw_coordinate_graph.png')\n",
    "plt.show()"
   ],
   "id": "39df3b2790641c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import folium\n",
    "\n",
    "m = folium.Map(location=[41.8719, 12.5674], zoom_start=6, zoom_control=True, scrollWheelZoom=False)\n",
    "folium.TileLayer('cartodbpositron').add_to(m)\n",
    "for k, pos in nx.get_node_attributes(OF_graph, 'pos').items(): #posizionamento nodi del grafo sulla mappa\n",
    "    tooltip = f\"{OF_graph.nodes[k]['Name']} ({k})\"\n",
    "    folium.CircleMarker(\n",
    "        location=[pos[1], pos[0]], #restituisce posizione nodo (lat e long)\n",
    "        radius=1,\n",
    "        color='red',\n",
    "        fill=True,\n",
    "        fill_color='red',\n",
    "        fill_opacity=0.5,\n",
    "        tooltip=tooltip\n",
    "    ).add_to(m)\n",
    "\n",
    "# add weighted edges\n",
    "for edge in OF_graph.edges(): # per ogni arco prende i due nodi collegati\n",
    "    node1 = edge[0]\n",
    "    node2 = edge[1]\n",
    "    try:\n",
    "        pos1 = OF_graph.nodes[node1]['pos'][::-1] #[::-1]da formato xy a lat long\n",
    "        pos2 = OF_graph.nodes[node2]['pos'][::-1]\n",
    "    except KeyError:\n",
    "        continue\n",
    "    #tooltip = f\"{OF_graph.nodes[node1][\"Name\"]} - {OF_graph.nodes[node2][\"Name\"]} ({OF_graph.edges[node1, node2]['weight']})\"\n",
    "    #tooltip scrive Aeroporto partenza (nodo1) - Aeroporto arrivo (nodo2) (Peso dell'arco)\n",
    "    tooltip = f\"{OF_graph.nodes[node1]['Name']} - {OF_graph.nodes[node2]['Name']} ({OF_graph.edges[node1, node2]['weight']})\"\n",
    "    weight = OF_graph.edges[node1, node2]['weight'] / 2\n",
    "    #divide per due (avanti ed indietro --> monodirezionale)\n",
    "\n",
    "    folium.PolyLine([pos1, pos2], color=\"blue\", weight=weight, opacity=0.2, tooltip=tooltip).add_to(m)\n",
    "m"
   ],
   "id": "6696584dcb5eda7e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "degree = dict(nx.degree(OF_graph))\n",
    "# print(\"Degree:\", degree)\n",
    "\n",
    "# Calculate the degree centrality of the nodes\n",
    "degree_centrality = nx.degree_centrality(OF_graph)\n",
    "# print(\"Degree Centrality:\", degree_centrality)\n",
    "\n",
    "betweenness_centrality = nx.betweenness_centrality(OF_graph, weight=\"weight\")\n",
    "# print(\"Betweenness Centrality:\", betweenness_centrality)\n",
    "\n",
    "eigenvector_centrality = nx.eigenvector_centrality(OF_graph, max_iter=1000, weight=\"weight\")\n",
    "# print(\"Eigenvector Centrality:\", eigenvector_centrality)\n",
    "\n",
    "closeness_centrality = nx.closeness_centrality(OF_graph, distance=\"distance\")\n",
    "# print(\"Closeness Centrality:\", closeness_centrality)\n",
    "\n",
    "clustering_coefficient = nx.clustering(OF_graph, weight=\"weight\")\n",
    "# print(\"Clustering Coefficient:\", clustering_coefficient)\n",
    "\n",
    "pagerank = nx.pagerank(OF_graph, weight=\"weight\")\n",
    "# print(\"Pagerank:\", pagerank)\n",
    "\n",
    "core_number = nx.core_number(OF_graph)\n",
    "# print(\"Core Numbers:\", core_number)"
   ],
   "id": "5fc6e07737455c0f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "density = nx.density(OF_graph) #densità del grafo\n",
    "print(\"Density:\", density)\n",
    "\n",
    "if nx.is_connected(OF_graph): #se grafo connesso\n",
    "    avg_path_length = nx.average_shortest_path_length(OF_graph, weight='distance') #lunghezza media del percorso\n",
    "    diameter = nx.diameter(OF_graph) #diametro = massima distanza dei nodi nel grafo\n",
    "    print(f\"Average path length: {avg_path_length}\")\n",
    "    print(f\"Diameter of network: {diameter}\")\n",
    "else:\n",
    "    avg_path_length = None\n",
    "    diameter = None\n",
    "\n",
    "connected_components = list(nx.connected_components(OF_graph)) #lista dei componenti connessi --> sottografi dei grafi\n",
    "connectedness = len(connected_components) #numero dei componenti trovati\n",
    "print(\"Number of Connected Components:\", connectedness)\n",
    "\n",
    "#COEFFICIENTE DI ASSORTIVITA'\n",
    "#nodi dello stesso livello a collegarsi tra loro: (\n",
    "    #.>0 --> nodi con gradi simili si collegano, .<0 --> nodi con gradi diversi si collegano)\n",
    "    #.=0 --> nodi dove non c'è correlazione\n",
    "assortativity = nx.degree_assortativity_coefficient(OF_graph)\n",
    "print(\"Assortativity:\", assortativity)\n",
    "\n",
    "#bridges --> arco critico\n",
    "bridges = list(nx.bridges(OF_graph))\n",
    "# print(\"Bridges:\", bridges)\n",
    "print(\"Number of bridges\", len(bridges))"
   ],
   "id": "bac9873922b63f12",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# create a dataframe with the metrics for each node\n",
    "df = pd.DataFrame([degree, degree_centrality, betweenness_centrality, eigenvector_centrality, closeness_centrality, clustering_coefficient, pagerank, core_number]).T\n",
    "\n",
    "# rename the columns\n",
    "df.columns = ['Degree', 'Degree Centrality', 'Betweenness Centrality', 'Eigenvector Centrality', 'Closeness Centrality', 'Clustering Coefficient', 'Pagerank', 'Core Number']\n",
    "\n",
    "# merge the dataframe with the airport data\n",
    "df = OF_airports.merge(df, right_index=True, left_on='Airport ID')\n",
    "df"
   ],
   "id": "6b1f553833af1b29",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Identification of the main hubs\n",
    "\n",
    "- Degree Centrality\n",
    "    - It measures the number of direct connections (routes) an airport has.\n",
    "    - High degree centrality identifies airports with the most direct routes and is a good first approximation of hub importance.\n",
    "- Betweenness Centrality\n",
    "    - It measures how often an airport lies on the shortest paths between other airports.\n",
    "    - High betweenness centrality highlights airports that act as intermediaries or key transit points.\n",
    "- Closeness Centrality\n",
    "    - It measures the average shortest path distance from an airport to all others.\n",
    "    - High closeness centrality identifies airports that can quickly reach all others, making them strategically located.\n",
    "- Eigenvector Centrality\n",
    "    - It measures the importance of an airport based on its connections to other important airports.\n",
    "    - Identifies influential hubs connected to other major hubs.\n",
    "- Pagerank\n",
    "    - It measures the importance of an airport based on the importance of its connections.\n",
    "    - Highlights influential nodes even if their connections are to less significant nodes.\n"
   ],
   "id": "8c5524d6e3e09d0c"
  },
  {
   "metadata": {},
   "id": "d8b250439509c65e",
   "outputId": "6e9bcc0a-bca4-44cc-f2b6-efeb74cf54b9",
   "cell_type": "code",
   "source": [
    "n_best = 10 #prende i primi 10 valori degli aeroporti per ogni metrica delle colonne\n",
    "\n",
    "columns = [\n",
    "    'Degree', 'Degree Centrality', 'Betweenness Centrality', 'Eigenvector Centrality',\n",
    "    'Closeness Centrality', 'Clustering Coefficient', 'Pagerank', 'Core Number'\n",
    "]\n",
    "titles = [\n",
    "    f'Top {n_best} airports with the highest degree',\n",
    "    f'Top {n_best} airports with the highest degree centrality',\n",
    "    f'Top {n_best} airports with the highest betweenness centrality',\n",
    "    f'Top {n_best} airports with the highest eigenvector centrality',\n",
    "    f'Top {n_best} airports with the highest closeness centrality',\n",
    "    f'Top {n_best} airports with the highest clustering coefficient',\n",
    "    f'Top {n_best} airports with the highest pagerank',\n",
    "    f'Top {n_best} airports with the highest core number'\n",
    "]\n",
    "\n",
    "# Imposta il numero di subplot\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))  # 2 righe, 4 colonne\n",
    "\n",
    "# Loop attraverso le colonne e i titoli\n",
    "for ax, col, title in zip(axes.flatten(), columns, titles):\n",
    "    ax: plt.Axes\n",
    "    data = df.sort_values(by=col, ascending=False).head(n_best)\n",
    "    sns.barplot(data=df.sort_values(by=col, ascending=False).head(n_best), x='Name', y=col, ax=ax)\n",
    "    ax.set_title(title)\n",
    "    ax.axes.xaxis.set_ticks(ax.get_xticks())\n",
    "    ax.set_xticklabels([f\"{city} ({iata})\" for city, iata in zip(data['City'], data['IATA/FAA'])], rotation=80)\n",
    "\n",
    "# Aggiungi spaziatura tra i subplot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "titles = [ #distrubuzioni delle metrice\n",
    "    'Degree distribution', 'Degree Centrality distribution', 'Betweenness Centrality distribution',\n",
    "    'Eigenvector Centrality distribution', 'Closeness Centrality distribution', 'Clustering Coefficient distribution',\n",
    "    'Pagerank distribution', 'Core Number distribution'\n",
    "]\n",
    "\n",
    "titles_linear = [f\"{t} in linear scale\" for t in titles]\n",
    "\n",
    "# Configura la figura con 2x4 subplot nella schermata\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "\n",
    "# Loop su colonne e titoli per creare gli istogrammi\n",
    "for ax, col, title in zip(axes.flatten()[:len(columns)], columns, titles_linear): #associazione dei subplot alla metrica corrispondente e titolo\n",
    "    sns.histplot(df[col], ax=ax, stat=\"density\", bins=20)\n",
    "    ax.set_title(title)\n",
    "    #df[col] -->prende i dati del dataframe per ogni colonna corrispondente\n",
    "    #stat=\"density\" --> istogramma come densità di probabilità normalizzato a 1\n",
    "    #bins = 20 -->  numero di intervalli (20)\n",
    "\n",
    "# Rimuovi eventuali assi inutilizzati nell'ultimo subplot\n",
    "if len(columns) < len(axes.flatten()):\n",
    "    for ax in axes.flatten()[len(columns):]:\n",
    "        ax.axis('off')\n",
    "\n",
    "# Adatta layout finale\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "520c4148e1f10b27",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Configura la figura con 2 righe e 4 colonne\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "\n",
    "titles_exp = [f\"{t} in log-log scale\" for t in titles]\n",
    "\n",
    "# Loop su colonne e titoli per creare i grafici\n",
    "for ax, col, title in zip(axes.flatten(), columns, titles_exp):\n",
    "    sns.histplot(df[col], ax=ax, stat=\"density\", bins=20, log_scale=True)\n",
    "    ax.set_yscale(\"log\")\n",
    "    # plot the distribution of the metrics with a log scale. in the vertical axis is visualized the fraction of nodes with that value\n",
    "    ax.set_ylim(0.0001, 5)\n",
    "    ax.set_title(title)\n",
    "\n",
    "# Adatta layout finale\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "f3216d9d27cb6fff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# powerlaw calculation\n",
    "fit: powerlaw.Fit = powerlaw.Fit(list(degree.values()), discrete=True)\n",
    "#adatta distribuzione dei gradi della rete ad una distribuzione di potenza\n",
    "#list(degree.values()) --> prende valori dei gradi dei nodi di un grafo e li converte in lista\n",
    "# discrete = True --> dati forniti sono discreti, cioè numeri interi come i grafi\n",
    "# self.alpha = 1 + (self.n / sum(log(data / (self.xmin - .5))))\n",
    "\n",
    "#Fase di fitting per capire se dati seguono una distribuzione o no\n",
    "#Stima di alpha --> parametro che caratterizza pendenza della distribuzione\n",
    "alpha = fit.power_law.alpha\n",
    "print(f'alpha has value: {alpha}')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "fit.plot_pdf(label='Probability Density Function (PDF)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "id": "49d99ee2c89be87",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Examine if highly connected airports have low clustering (common for hubs)\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.scatterplot(data=df, ax=ax, x='Degree', y='Clustering Coefficient')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "plt.xlabel('Degree')\n",
    "plt.ylabel('Clustering Coefficient')\n",
    "plt.title('Clustering Coefficient vs Degree')\n",
    "plt.show()"
   ],
   "id": "1b5ef887c616bfe0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Identification of regional clusters"
   ],
   "id": "49e4947507a86d51"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Compute the best partition using the Louvain method\n",
    "# partition = community_louvain.best_partition(OF_graph)\n",
    "clusters_list = nx.community.louvain_communities(OF_graph, weight='weight')\n",
    "clusters = {}\n",
    "for i, cluster in enumerate(clusters_list):\n",
    "    clusters[i] = cluster\n",
    "\n",
    "partition = {}\n",
    "for cluster_id, airport_ids in clusters.items():\n",
    "    for airport_id in airport_ids:\n",
    "        partition[airport_id] = cluster_id\n",
    "\n",
    "\n",
    "# Assign community as a node attribute\n",
    "nx.set_node_attributes(OF_graph, partition, 'community')\n",
    "\n",
    "# Get the position for nodes\n",
    "pos = nx.get_node_attributes(OF_graph, 'pos')\n",
    "\n",
    "# Generate a color map for different communities\n",
    "# cmap = cm.get_cmap('viridis', max(partition.values()) + 1)\n",
    "cmap = plt.get_cmap(\"viridis\", 7)\n",
    "\n",
    "\n",
    "# Plot the graph, coloring nodes based on their community\n",
    "url = \"https://naciscdn.org/naturalearth/110m/cultural/ne_110m_admin_0_countries.zip\"\n",
    "world: gpd.GeoDataFrame = gpd.read_file(url)\n",
    "world.plot(figsize=(90,40), edgecolor='gray', alpha=0.5, color='gray')\n",
    "nx.draw_networkx_nodes(OF_graph, pos, partition.keys(), node_size=90, cmap=cmap, node_color=list(partition.values()), margins=0)\n",
    "nx.draw_networkx_edges(OF_graph, pos, alpha=0.1)\n",
    "plt.title('Regional clusters (communities) in the airport network', fontsize=50)\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/community_clustering_graph.png')\n",
    "# plt.show()\n",
    "\n",
    "# Stampa per ogni cluster gli ID e i nomi degli aeroporti appartenenti\n",
    "for cluster_id, airport_ids in clusters.items():\n",
    "    airport_names = [airport_dict[airport_id]['City'] for airport_id in airport_ids]\n",
    "    print(f\"Cluster {cluster_id}: {airport_names}\")\n",
    "\n",
    "# Optionally, print out the community assignment for each node\n",
    "#for airport_id, community_id in partition.items():\n",
    "    #print(f\"Airport ID {airport_id} is in community {community_id}\")"
   ],
   "id": "ed929c960fdf5a76",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Robustness simulation"
   ],
   "id": "80e23e52753654ba"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Calcolo della Connettività",
   "id": "3688bcbb5ce567e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "initial_connectivity = nx.node_connectivity(OF_graph)\n",
    "print(f'Initial connectivity: {initial_connectivity}')\n",
    "\n",
    "# Rimozione degli hub e ricalcolo della connettività\n",
    "hubs = df.sort_values(by='Degree', ascending=False).head(10)['Airport ID']\n",
    "OF_graph_removed_hubs = OF_graph.copy()\n",
    "OF_graph_removed_hubs.remove_nodes_from(hubs)\n",
    "connectivity_after_hub_removal = nx.node_connectivity(OF_graph_removed_hubs)\n",
    "print(f'Connectivity after removing hubs: {connectivity_after_hub_removal}')\n"
   ],
   "id": "3478e5827b0b9cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Calcolo della Frammentazione",
   "id": "ba667b33e09b1c22"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "largest_cc = max(nx.connected_components(OF_graph), key=len)\n",
    "fragmentation = 1 - (len(largest_cc) / OF_graph.number_of_nodes())\n",
    "print(f'Fragmentation before removing hubs: {fragmentation}')\n",
    "\n",
    "largest_cc = max(nx.connected_components(OF_graph_removed_hubs), key=len)\n",
    "fragmentation = 1 - (len(largest_cc) / OF_graph_removed_hubs.number_of_nodes())\n",
    "print(f'Fragmentation after removing hubs: {fragmentation}')"
   ],
   "id": "5e380e08c8704460",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Calcolo della Compattezza",
   "id": "7907a7367393f86"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if nx.is_connected(OF_graph):\n",
    "    initial_compactness = 1 / nx.average_shortest_path_length(OF_graph)\n",
    "    print(f'Initial compactness: {initial_compactness}')\n",
    "\n",
    "if nx.is_connected(OF_graph_removed_hubs):\n",
    "    compactness_after_hub_removal = 1 / nx.average_shortest_path_length(OF_graph_removed_hubs)\n",
    "    print(f'Compactness after removing hubs: {compactness_after_hub_removal}')\n",
    "else:\n",
    "    print(\"The graph is no longer connected after removing hubs.\")\n",
    "    component_number = len([c for c in nx.connected_components(OF_graph_removed_hubs)])\n",
    "    print(f\"Now the graph has {component_number} component\")\n"
   ],
   "id": "18a9edea019e5a8c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Analisi della Centralità",
   "id": "201cee30eb3c93e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "betweenness_before = nx.betweenness_centrality(OF_graph)\n",
    "betweenness_after = nx.betweenness_centrality(OF_graph_removed_hubs)\n",
    "\n",
    "# Analizza la variazione nella betweenness centrality\n",
    "changes = {\n",
    "    node: betweenness_after[node] - betweenness_before[node]\n",
    "    for node in betweenness_before.keys() & betweenness_after.keys()\n",
    "}\n",
    "\n",
    "biggest_changes = sorted(changes.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "print(biggest_changes)\n",
    "\n",
    "# filter df with the biggest changes\n",
    "df_biggest_changes = df[df['Airport ID'].isin([k for k, v in biggest_changes])]\n",
    "df_biggest_changes"
   ],
   "id": "cf6b9311a6e3450c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sorted(betweenness_after.items(), key=lambda x: x[1], reverse=True)[:10]",
   "id": "aa380f2a9a7915a2",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
