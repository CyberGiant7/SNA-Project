{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install powerlaw"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "00m_OKSxjN4C",
    "outputId": "2cd8e2ac-53c3-472f-84d2-2a3af74c3ffb"
   },
   "id": "00m_OKSxjN4C",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "id": "initial_id"
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import powerlaw\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "226998357227b431"
   },
   "cell_type": "code",
   "source": [
    "# Load OpenFlights airport data from the CSV file\n",
    "OF_airports = pd.read_csv(\n",
    "    \"data/airports.dat\",  # Path to the airports data file\n",
    "    header=None,  # Indicates there are no headers in the file\n",
    "    names=[\"Airport ID\", \"Name\", \"City\", \"Country\", \"IATA/FAA\",\n",
    "           \"ICAO\", \"Latitude\", \"Longitude\", \"Altitude\", \"Timezone\", \"DST\",\n",
    "           \"Tz database timezone\", \"Type\", \"Source\"],  # Custom column names in the CSV of airports\n",
    "    sep=\",\"  # Columns are separated by commas\n",
    ")\n",
    "\n",
    "# Load OpenFlights routes data from the CSV file\n",
    "OF_routes = pd.read_csv(\n",
    "    \"data/routes.dat\",  # Path to the routes data file\n",
    "    header=None,  # Indicates there are no headers in the file\n",
    "    names=[\"Airline\", \"Airline ID\", \"Source airport\", \"Source airport ID\",\n",
    "           \"Destination airport\", \"Destination airport ID\",\n",
    "           \"Codeshare\", \"Stops\", \"Equipment\"]  # Custom column names in the CSV of the routes\n",
    ")\n",
    "\n",
    "# Filter and clean OpenFlights data\n",
    "OF_routes = OF_routes[OF_routes['Codeshare'].notnull()]  # Keep only rows with non-null codeshare values\n",
    "OF_routes = OF_routes[OF_routes['Source airport ID'] != \"\\\\N\"]  # Exclude rows where Source airport ID is missing\n",
    "OF_routes = OF_routes[OF_routes['Destination airport ID'] != \"\\\\N\"]  # Exclude rows where Destination airport ID is missing\n",
    "OF_routes = OF_routes[OF_routes['Source airport ID'] != OF_routes['Destination airport ID']]  # Exclude self-loops (routes where source = destination)\n",
    "\n",
    "# Create weighted OpenFlights network\n",
    "# Based on the route we weighted it\n",
    "OF_routes = OF_routes.groupby(['Source airport ID', 'Destination airport ID']) \\\n",
    "    .size() \\\n",
    "    .reset_index(name='w')  # Count the number of routes between each pair of airports and assign as weight\n",
    "OF_routes.columns = ['i', 'j', 'w']  # Rename columns for clarity\n",
    "OF_routes['i'] = OF_routes['i'].astype(int)  # Ensure the source airport IDs are integers\n",
    "OF_routes['j'] = OF_routes['j'].astype(int)  # Ensure the destination airport IDs are integers\n",
    "OF_routes['w'] = OF_routes['w'].astype(int)  # Ensure the weights are integers\n",
    "\n",
    "# Symmetrize the network by summing the weights of bidirectional edges\n",
    "OF_routes = (\n",
    "    pd.concat([\n",
    "        OF_routes,  # Original data\n",
    "        OF_routes.rename(columns={'i': 'j', 'j': 'i'})  # Swap source and destination columns\n",
    "    ])\n",
    "    .groupby(['i', 'j'], as_index=False)\n",
    "    .agg({'w': 'sum'})  # Sum weights of bidirectional edges\n",
    ")\n",
    "\n",
    "# Keep only one direction of the edge (i < j)\n",
    "OF_routes = OF_routes[OF_routes['i'] < OF_routes['j']]\n",
    "\n",
    "# Filter OF_routes to keep only the routes with airports listed in OF_airports\n",
    "OF_routes = OF_routes[OF_routes['i'].isin(OF_airports['Airport ID'])]  # Keep edges where the source airport exists in the airport dataset\n",
    "OF_routes = OF_routes[OF_routes['j'].isin(OF_airports['Airport ID'])]  # Keep edges where the destination airport exists in the airport dataset\n",
    "\n",
    "# Build the OpenFlights graph\n",
    "OF_graph = nx.Graph()  # Initialize an undirected graph\n",
    "for _, row in OF_routes.iterrows():\n",
    "    OF_graph.add_edge(int(row['i']), int(row['j']), weight=row['w'])  # Add edges with weights to the graph\n"
   ],
   "id": "226998357227b431",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load the graph from the file\n",
    "# OF_graph = nx.read_weighted_edgelist('data/openflights.dl')\n",
    "\n",
    "# # Filter the graph to keep only the largest connected component\n",
    "# list_of_component = [c for c in nx.connected_components(OF_graph)]\n",
    "# print(f'Number of connected components: {len(list_of_component)}')\n",
    "# # Sort the list of connected components by length\n",
    "# list_of_component = sorted(list_of_component, key=len, reverse=True)\n",
    "#\n",
    "# # Print the number of nodes in the largest connected component\n",
    "# print(f'Number of nodes in the largest connected component: {len(list_of_component[0])}')\n",
    "# # Keep only the largest connected component\n",
    "# OF_graph = OF_graph.subgraph(list_of_component[0])\n",
    "\n",
    "# Print the number of nodes and edges\n",
    "print(f'Number of nodes: {OF_graph.number_of_nodes()}')\n",
    "print(f'Number of edges: {OF_graph.number_of_edges()}')\n"
   ],
   "id": "50cc614140480928",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# create a dictionary in which the keys are the airport name and the values are the value of the airport in df\n",
    "airport_dict = OF_airports.set_index('Airport ID').T.to_dict()\n",
    "\n",
    "# set the attribute for each node in the graph\n",
    "nx.set_node_attributes(OF_graph, airport_dict)"
   ],
   "id": "fe09051e9b20f3bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "labels = nx.get_node_attributes(OF_graph, 'Name')\n",
    "fig = plt.figure(figsize=(120, 80))\n",
    "# Plot the graph with more space between nodes\n",
    "# nx.draw_networkx(OF_graph, node_size=10, edge_color='gray', alpha=0.5, with_labels=True, labels=labels)\n",
    "nx.draw_networkx(OF_graph, node_size=10, edge_color='gray', alpha=0.5, with_labels=False)\n",
    "plt.title('Airport and flight network', fontsize=15)\n",
    "plt.savefig('images/networkx_graph.png')\n",
    "plt.show()"
   ],
   "id": "c44fb9ae12385c76",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for node in OF_graph.nodes():\n",
    "    x = airport_dict[node]['Longitude']\n",
    "    y = airport_dict[node]['Latitude']\n",
    "    pos = (x, y)\n",
    "    OF_graph.nodes[node]['pos'] = pos\n",
    "\n",
    "# Ottieni le posizioni dei nodi\n",
    "pos = nx.get_node_attributes(OF_graph, 'pos')\n",
    "labels = nx.get_node_attributes(OF_graph, 'Name')\n",
    "\n",
    "g2 = nx.subgraph(OF_graph, list(pos.keys()))\n",
    "\n",
    "# Disegna il grafo\n",
    "#plt.figure(figsize=(100, 50))\n",
    "plt.figure(figsize=(75,37.5))\n",
    "nx.draw(\n",
    "    g2, pos,\n",
    "    with_labels=True,\n",
    "    #node_color='skyblue',\n",
    "    node_color='red',\n",
    "    node_size=90,\n",
    "    font_size=10,\n",
    "    font_color='darkblue',\n",
    "    edge_color='gray',\n",
    "    width=0.5,\n",
    "    alpha=0.7,\n",
    "    labels=labels\n",
    ")\n",
    "#font_size=10,\n",
    "    #node_size=60,\n",
    "plt.title('Airport and flight network', fontsize=15)\n",
    "plt.savefig('images/networkx_draw_coordinate_graph.png')\n",
    "plt.show()"
   ],
   "id": "39df3b2790641c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import folium\n",
    "\n",
    "m = folium.Map(location=[41.8719, 12.5674], zoom_start=6, zoom_control=True, scrollWheelZoom=False)\n",
    "folium.TileLayer('cartodbpositron').add_to(m)\n",
    "for k, pos in nx.get_node_attributes(OF_graph, 'pos').items(): #posizionamento nodi del grafo sulla mappa\n",
    "    tooltip = f\"{OF_graph.nodes[k]['Name']} ({k})\"\n",
    "    folium.CircleMarker(\n",
    "        location=[pos[1], pos[0]], #restituisce posizione nodo (lat e long)\n",
    "        radius=1,\n",
    "        color='red',\n",
    "        fill=True,\n",
    "        fill_color='red',\n",
    "        fill_opacity=0.5,\n",
    "        tooltip=tooltip\n",
    "    ).add_to(m)\n",
    "\n",
    "# add weighted edges\n",
    "for edge in OF_graph.edges(): # per ogni arco prende i due nodi collegati\n",
    "    node1 = edge[0]\n",
    "    node2 = edge[1]\n",
    "    try:\n",
    "        pos1 = OF_graph.nodes[node1]['pos'][::-1] #[::-1]da formato xy a lat long\n",
    "        pos2 = OF_graph.nodes[node2]['pos'][::-1]\n",
    "    except KeyError:\n",
    "        continue\n",
    "    #tooltip = f\"{OF_graph.nodes[node1][\"Name\"]} - {OF_graph.nodes[node2][\"Name\"]} ({OF_graph.edges[node1, node2]['weight']})\"\n",
    "    #tooltip scrive Aeroporto partenza (nodo1) - Aeroporto arrivo (nodo2) (Peso dell'arco)\n",
    "    tooltip = f\"{OF_graph.nodes[node1]['Name']} - {OF_graph.nodes[node2]['Name']} ({OF_graph.edges[node1, node2]['weight']})\"\n",
    "    weight = OF_graph.edges[node1, node2]['weight'] / 2\n",
    "    #divide per due (avanti ed indietro --> monodirezionale)\n",
    "\n",
    "    folium.PolyLine([pos1, pos2], color=\"blue\", weight=weight, opacity=0.2, tooltip=tooltip).add_to(m)\n",
    "m"
   ],
   "id": "6696584dcb5eda7e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "degree = dict(nx.degree(OF_graph))\n",
    "# print(\"Degree:\", degree)\n",
    "\n",
    "# Calculate the degree centrality of the nodes\n",
    "degree_centrality = nx.degree_centrality(OF_graph)\n",
    "# print(\"Degree Centrality:\", degree_centrality)\n",
    "\n",
    "betweenness_centrality = nx.betweenness_centrality(OF_graph)\n",
    "# print(\"Betweenness Centrality:\", betweenness_centrality)\n",
    "\n",
    "eigenvector_centrality = nx.eigenvector_centrality(OF_graph, max_iter=1000)\n",
    "# print(\"Eigenvector Centrality:\", eigenvector_centrality)\n",
    "\n",
    "closeness_centrality = nx.closeness_centrality(OF_graph)\n",
    "# print(\"Closeness Centrality:\", closeness_centrality)\n",
    "\n",
    "clustering_coefficient = nx.clustering(OF_graph)\n",
    "# print(\"Clustering Coefficient:\", clustering_coefficient)\n",
    "\n",
    "pagerank = nx.pagerank(OF_graph)\n",
    "# print(\"Pagerank:\", pagerank)\n",
    "\n",
    "core_number = nx.core_number(OF_graph)\n",
    "# print(\"Core Numbers:\", core_number)"
   ],
   "id": "5fc6e07737455c0f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "density = nx.density(OF_graph) #densità del grafo\n",
    "print(\"Density:\", density)\n",
    "\n",
    "if nx.is_connected(OF_graph): #se grafo connesso\n",
    "    avg_path_length = nx.average_shortest_path_length(OF_graph) #lunghezza media del percorso\n",
    "    diameter = nx.diameter(OF_graph) #diametro = massima distanza dei nodi nel grafo\n",
    "else:\n",
    "    avg_path_length = None\n",
    "    diameter = None\n",
    "\n",
    "connected_components = list(nx.connected_components(OF_graph)) #lista dei componenti connessi --> sottografi dei grafi\n",
    "connectedness = len(connected_components) #numero dei componenti trovati\n",
    "print(\"Number of Connected Components:\", connectedness)\n",
    "\n",
    "#COEFFICIENTE DI ASSORTIVITA'\n",
    "#nodi dello stesso livello a collegarsi tra loro: (\n",
    "    #.>0 --> nodi con gradi simili si collegano, .<0 --> nodi con gradi diversi si collegano)\n",
    "    #.=0 --> nodi dove non c'è correlazione\n",
    "assortativity = nx.degree_assortativity_coefficient(OF_graph)\n",
    "print(\"Assortativity:\", assortativity)\n",
    "\n",
    "#bridges --> arco critico\n",

    "bridges = list(nx.bridges(OF_graph))\n",
    "# print(\"Bridges:\", bridges)\n",
    "print(\"Number of bridges\", len(bridges))"
   ],
   "id": "bac9873922b63f12",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# create a dataframe with the metrics for each node\n",
    "df = pd.DataFrame([degree, degree_centrality, betweenness_centrality, eigenvector_centrality, closeness_centrality, clustering_coefficient, pagerank, core_number]).T\n",
    "\n",
    "# rename the columns\n",
    "df.columns = ['Degree', 'Degree Centrality', 'Betweenness Centrality', 'Eigenvector Centrality', 'Closeness Centrality', 'Clustering Coefficient', 'Pagerank', 'Core Number']\n",
    "\n",
    "# merge the dataframe with the airport data\n",
    "df = OF_airports.merge(df, right_index=True, left_on='Airport ID')\n",
    "df"
   ],
   "id": "6b1f553833af1b29",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Identification of the main hubs\n",
    "\n",
    "- Degree Centrality\n",
    "    - It measures the number of direct connections (routes) an airport has.\n",
    "    - High degree centrality identifies airports with the most direct routes and is a good first approximation of hub importance.\n",
    "- Betweenness Centrality\n",
    "    - It measures how often an airport lies on the shortest paths between other airports.\n",
    "    - High betweenness centrality highlights airports that act as intermediaries or key transit points.\n",
    "- Closeness Centrality\n",
    "    - It measures the average shortest path distance from an airport to all others.\n",
    "    - High closeness centrality identifies airports that can quickly reach all others, making them strategically located.\n",
    "- Eigenvector Centrality\n",
    "    - It measures the importance of an airport based on its connections to other important airports.\n",
    "    - Identifies influential hubs connected to other major hubs.\n",
    "- Pagerank\n",
    "    - It measures the importance of an airport based on the importance of its connections.\n",
    "    - Highlights influential nodes even if their connections are to less significant nodes.\n"
   ],
   "id": "8c5524d6e3e09d0c"
  },
  {
    "metadata": {},
    "id": "d8b250439509c65e",
    "outputId": "6e9bcc0a-bca4-44cc-f2b6-efeb74cf54b9"
   },
   "cell_type": "code",
   "source": [
    "n_best = 10 #prende i primi 10 valori degli aeroporti per ogni metrica delle colonne\n",
    "\n",
    "columns = [\n",
    "    'Degree', 'Degree Centrality', 'Betweenness Centrality', 'Eigenvector Centrality',\n",
    "    'Closeness Centrality', 'Clustering Coefficient', 'Pagerank', 'Core Number'\n",
    "]\n",
    "titles = [\n",
    "    f'Top {n_best} airports with the highest degree',\n",
    "    f'Top {n_best} airports with the highest degree centrality',\n",
    "    f'Top {n_best} airports with the highest betweenness centrality',\n",
    "    f'Top {n_best} airports with the highest eigenvector centrality',\n",
    "    f'Top {n_best} airports with the highest closeness centrality',\n",
    "    f'Top {n_best} airports with the highest clustering coefficient',\n",
    "    f'Top {n_best} airports with the highest pagerank',\n",
    "    f'Top {n_best} airports with the highest core number'\n",
    "]\n",
    "\n",
    "# Imposta il numero di subplot\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))  # 2 righe, 4 colonne\n",
    "\n",
    "# Loop attraverso le colonne e i titoli\n",
    "for ax, col, title in zip(axes.flatten(), columns, titles):\n",
    "    ax: plt.Axes\n",
    "    sns.barplot(data=df.sort_values(by=col, ascending=False).head(n_best), x='City', y=col, ax=ax)\n",
    "    ax.set_title(title)\n",
    "    ax.axes.xaxis.set_ticks(ax.get_xticks())\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=70)\n",
    "\n",
    "# Aggiungi spaziatura tra i subplot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "d8b250439509c65e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "titles = [ #distrubuzioni delle metrice\n",
    "    'Degree distribution', 'Degree Centrality distribution', 'Betweenness Centrality distribution',\n",
    "    'Eigenvector Centrality distribution', 'Closeness Centrality distribution', 'Clustering Coefficient distribution',\n",
    "    'Pagerank distribution', 'Core Number distribution'\n",
    "]\n",
    "\n",
    "titles_linear = [f\"{t} in linear scale\" for t in titles]\n",
    "\n",
    "# Configura la figura con 2x4 subplot nella schermata\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "\n",
    "# Loop su colonne e titoli per creare gli istogrammi\n",
    "for ax, col, title in zip(axes.flatten()[:len(columns)], columns, titles_linear): #associazione dei subplot alla metrica corrispondente e titolo\n",
    "    sns.histplot(df[col], ax=ax, stat=\"density\", bins=20)\n",
    "    ax.set_title(title)\n",
    "    #df[col] -->prende i dati del dataframe per ogni colonna corrispondente\n",
    "    #stat=\"density\" --> istogramma come densità di probabilità normalizzato a 1\n",
    "    #bins = 20 -->  numero di intervalli (20)\n",
    "\n",
    "# Rimuovi eventuali assi inutilizzati nell'ultimo subplot\n",
    "if len(columns) < len(axes.flatten()):\n",
    "    for ax in axes.flatten()[len(columns):]:\n",
    "        ax.axis('off')\n",
    "\n",
    "# Adatta layout finale\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "520c4148e1f10b27",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Configura la figura con 2 righe e 4 colonne\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "\n",
    "titles_exp = [f\"{t} in log-log scale\" for t in titles]\n",
    "\n",
    "# Loop su colonne e titoli per creare i grafici\n",
    "for ax, col, title in zip(axes.flatten(), columns, titles_exp):\n",
    "    sns.histplot(df[col], ax=ax, stat=\"density\", bins=20, log_scale=True)\n",
    "    ax.set_yscale(\"log\")\n",
    "    # plot the distribution of the metrics with a log scale. in the vertical axis is visualized the fraction of nodes with that value\n",
    "    ax.set_ylim(0.0001, 5)\n",
    "    ax.set_title(title)\n",
    "\n",
    "# Adatta layout finale\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "f3216d9d27cb6fff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# powerlaw calculation\n",
    "fit: powerlaw.Fit = powerlaw.Fit(list(degree.values()), discrete=True)\n",
    "#adatta distribuzione dei gradi della rete ad una distribuzione di potenza\n",
    "#list(degree.values()) --> prende valori dei gradi dei nodi di un grafo e li converte in lista\n",
    "# discrete = True --> dati forniti sono discreti, cioè numeri interi come i grafi\n",
    "# self.alpha = 1 + (self.n / sum(log(data / (self.xmin - .5))))\n",
    "\n",
    "#Fase di fitting per capire se dati seguono una distribuzione o no\n",
    "#Stima di alpha --> parametro che caratterizza pendenza della distribuzione\n",
    "alpha = fit.power_law.alpha\n",
    "print(f'alpha has value: {alpha}')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "fit.plot_pdf(label='Probability Density Function (PDF)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "id": "49d99ee2c89be87",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Examine if highly connected airports have low clustering (common for hubs)\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.scatterplot(data=df, ax=ax, x='Degree', y='Clustering Coefficient')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "plt.xlabel('Degree')\n",
    "plt.ylabel('Clustering Coefficient')\n",
    "plt.title('Clustering Coefficient vs Degree')\n",
    "plt.show()"
   ],
   "id": "1b5ef887c616bfe0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Identification of regional clusters"
   ],
   "id": "49e4947507a86d51"
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install python-louvain"
   ],
   "metadata": {}
   },
   "id": "bMvZ_o-Y3dHI",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Import necessary libraries for community detection\n",
    "import community as community_louvain  # Louvain method for community detection\n",
    "import matplotlib.cm as cm\n",
    "import community.community_louvain as community_louvain  # Corretta l'importazione\n",
    "\n",
    "\n",
    "# Compute the best partition using the Louvain method\n",
    "partition = community_louvain.best_partition(OF_graph)\n",
    "\n",
    "# Assign community as a node attribute\n",
    "nx.set_node_attributes(OF_graph, partition, 'community')\n",
    "\n",
    "# Get the position for nodes\n",
    "pos = nx.get_node_attributes(OF_graph, 'pos')\n",
    "\n",
    "# Generate a color map for different communities\n",
    "cmap = cm.get_cmap('viridis', max(partition.values()) + 1)\n",
    "\n",
    "# Plot the graph, coloring nodes based on their community\n",
    "plt.figure(figsize=(75, 37.5))\n",
    "nx.draw_networkx_nodes(OF_graph, pos, partition.keys(), node_size=90,\n",
    "                       cmap=cmap, node_color=list(partition.values()))\n",
    "nx.draw_networkx_edges(OF_graph, pos, alpha=0.5)\n",
    "nx.draw_networkx_labels(OF_graph, pos, labels=labels, font_size=10, font_color='darkblue')\n",
    "\n",
    "plt.title('Regional clusters (communities) in the airport network', fontsize=15)\n",
    "plt.savefig('images/community_clustering_graph.png')\n",
    "plt.show()\n",
    "\n",
    "clusters = {}\n",
    "\n",
    "# Iteriamo su ciascun nodo e lo raggruppiamo nel rispettivo cluster\n",
    "for airport_id, cluster_id in partition.items():\n",
    "    if cluster_id not in clusters:\n",
    "        clusters[cluster_id] = []\n",
    "    clusters[cluster_id].append(airport_id)\n",
    "\n",
    "# Stampa per ogni cluster gli ID e i nomi degli aeroporti appartenenti\n",
    "for cluster_id, airport_ids in clusters.items():\n",
    "    airport_names = [airport_dict[airport_id]['Name'] for airport_id in airport_ids]\n",
    "    print(f\"Cluster {cluster_id}: {airport_names}\")\n",
    "\n",
    "# Optionally, print out the community assignment for each node\n",
    "#for airport_id, community_id in partition.items():\n",
    "    #print(f\"Airport ID {airport_id} is in community {community_id}\")\n",
    "\n"
   ],
   "id": "da90157f657ae210",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Robustness simulation"
   ],
   "id": "80e23e52753654ba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [],
   "id": "3478e5827b0b9cc",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
